{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the dataset: 506\n",
      "\n",
      "Features in the dataset:\n",
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'B', 'LSTAT'],\n",
      "      dtype='object')\n",
      "\n",
      "Minimum price in the dataset: 5.0\n",
      "Maximum price in the dataset: 50.0\n",
      "\n",
      "\n",
      "Mean Squared Error: 24.29\n",
      "R-squared: 0.67\n",
      "\n",
      "\n",
      "Predicted Price for new data: 27.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston_data = load_boston()\n",
    "data = pd.DataFrame(boston_data.data, columns=boston_data.feature_names)\n",
    "data['PRICE'] = boston_data.target\n",
    "\n",
    "# Display information about the dataset\n",
    "data_info = f\"Number of samples in the dataset: {len(data)}\\n\\nFeatures in the dataset:\\n{data.columns[:-1]}\"\n",
    "price_info = f\"\\n\\nMinimum price in the dataset: {data['PRICE'].min()}\\nMaximum price in the dataset: {data['PRICE'].max()}\"\n",
    "\n",
    "# Display information about the features and data length in a Markdown cell\n",
    "print(data_info + price_info)\n",
    "\n",
    "# Prepare the data\n",
    "X = data.drop('PRICE', axis=1)\n",
    "y = data['PRICE']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Display the model's performance metrics in a Markdown cell\n",
    "metrics_info = f\"\\n\\nMean Squared Error: {mse:.2f}\\nR-squared: {r2:.2f}\"\n",
    "print(metrics_info)\n",
    "\n",
    "# Use the model for predictions\n",
    "new_data = np.array([[0.1, 18.0, 5.0, 0, 0.538, 6.0, 65.2, 4.0900, 1, 296.0, 15.3, 396.9, 4.98]])\n",
    "predicted_price = model.predict(new_data)[0]\n",
    "\n",
    "# Display the predicted price in a Markdown cell\n",
    "prediction_info = f\"\\n\\nPredicted Price for new data: {predicted_price:.2f}\"\n",
    "print(prediction_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
